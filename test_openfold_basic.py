#!/usr/bin/env python3
"""
OpenFoldåŸºç¡€åŠŸèƒ½æµ‹è¯•ï¼ˆæ— éœ€é¢„è®­ç»ƒå‚æ•°ï¼‰
æµ‹è¯•æ¨¡å‹ç»“æ„å’Œæ•°æ®å¤„ç†ç®¡é“
"""

import torch
import numpy as np
from openfold.model.model import AlphaFold
from openfold.data import data_transforms
from openfold.config import model_config
import ml_collections

def test_model_creation():
    """æµ‹è¯•æ¨¡å‹åˆ›å»º"""
    print("=== æµ‹è¯•AlphaFoldæ¨¡å‹åˆ›å»º ===")
    
    try:
        # è·å–é»˜è®¤é…ç½®
        config = model_config("model_1")
        print(f"âœ… åŠ è½½é…ç½®: {config.model.evoformer_stack.num_blocks}å±‚Evoformer")
        
        # åˆ›å»ºæ¨¡å‹
        model = AlphaFold(config)
        print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"   - å‚æ•°æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
        print(f"   - å¯è®­ç»ƒå‚æ•°: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
        
        return True
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
        return False

def test_data_transforms():
    """æµ‹è¯•æ•°æ®å˜æ¢"""
    print("\n=== æµ‹è¯•æ•°æ®å˜æ¢ç®¡é“ ===")
    
    try:
        # åˆ›å»ºç¤ºä¾‹ç‰¹å¾
        batch = {
            'aatype': torch.randint(0, 20, (1, 100)),  # æ°¨åŸºé…¸åºåˆ—
            'residue_index': torch.arange(100).unsqueeze(0),
            'seq_length': torch.tensor([100]),
            'msa': torch.randint(0, 22, (1, 32, 100)),  # MSA
            'num_alignments': torch.tensor([32]),
        }
        
        print(f"âœ… åˆ›å»ºç¤ºä¾‹è¾“å…¥æ•°æ®:")
        print(f"   - åºåˆ—é•¿åº¦: {batch['seq_length'].item()}")
        print(f"   - MSAæ·±åº¦: {batch['num_alignments'].item()}")
        
        # æµ‹è¯•ä¸€äº›åŸºæœ¬å˜æ¢
        from openfold.data.data_transforms import make_atom14_masks
        atom14_mask = make_atom14_masks(batch)
        print(f"âœ… Atom14æ©ç åˆ›å»ºæˆåŠŸ: {atom14_mask.shape}")
        
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®å˜æ¢æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_cuda_kernels():
    """æµ‹è¯•CUDAå†…æ ¸"""
    print("\n=== æµ‹è¯•CUDAåŠ é€Ÿå†…æ ¸ ===")
    
    if not torch.cuda.is_available():
        print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œè·³è¿‡CUDAå†…æ ¸æµ‹è¯•")
        return True
    
    try:
        from openfold.utils.kernel.attention_core import attention_core_inplace_cuda
        print("âœ… CUDAæ³¨æ„åŠ›å†…æ ¸å¯¼å…¥æˆåŠŸ")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        device = torch.device("cuda")
        batch_size, seq_len, dim = 2, 64, 128
        
        q = torch.randn(batch_size, seq_len, dim, device=device, dtype=torch.float32)
        k = torch.randn(batch_size, seq_len, dim, device=device, dtype=torch.float32)
        v = torch.randn(batch_size, seq_len, dim, device=device, dtype=torch.float32)
        bias = torch.zeros(batch_size, seq_len, seq_len, device=device, dtype=torch.float32)
        
        print(f"âœ… CUDAå¼ é‡åˆ›å»ºæˆåŠŸ: {q.shape}")
        print(f"   - è®¾å¤‡: {q.device}")
        print(f"   - æ•°æ®ç±»å‹: {q.dtype}")
        
        return True
    except Exception as e:
        print(f"âŒ CUDAå†…æ ¸æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_forward_pass():
    """æµ‹è¯•å‰å‘ä¼ æ’­ï¼ˆå°è§„æ¨¡ï¼‰"""
    print("\n=== æµ‹è¯•å°è§„æ¨¡å‰å‘ä¼ æ’­ ===")
    
    try:
        # ä½¿ç”¨æœ€å°é…ç½®
        config = model_config("model_1")
        # å‡å°æ¨¡å‹å°ºå¯¸ä»¥èŠ‚çœå†…å­˜
        config.model.evoformer_stack.num_blocks = 2
        config.model.structure_module.num_layer = 2
        
        model = AlphaFold(config)
        if torch.cuda.is_available():
            model = model.cuda()
            device = torch.device("cuda")
            print("âœ… æ¨¡å‹ç§»è‡³GPU")
        else:
            device = torch.device("cpu")
            print("âœ… ä½¿ç”¨CPUæ¨¡å¼")
        
        # åˆ›å»ºå°çš„æµ‹è¯•è¾“å…¥
        seq_len = 32
        msa_depth = 8
        
        batch = {
            'aatype': torch.randint(0, 20, (1, seq_len), device=device),
            'residue_index': torch.arange(seq_len, device=device).unsqueeze(0),
            'seq_length': torch.tensor([seq_len], device=device),
            'msa': torch.randint(0, 22, (1, msa_depth, seq_len), device=device),
            'num_alignments': torch.tensor([msa_depth], device=device),
            'msa_mask': torch.ones((1, msa_depth, seq_len), device=device),
            'seq_mask': torch.ones((1, seq_len), device=device),
            'template_aatype': torch.zeros((1, 0, seq_len), device=device, dtype=torch.long),
            'template_all_atom_positions': torch.zeros((1, 0, seq_len, 37, 3), device=device),
            'template_all_atom_mask': torch.zeros((1, 0, seq_len, 37), device=device),
            'template_mask': torch.zeros((1, 0), device=device),
            'template_pseudo_beta': torch.zeros((1, 0, seq_len, 3), device=device),
            'template_pseudo_beta_mask': torch.zeros((1, 0, seq_len), device=device),
            'extra_msa': torch.zeros((1, 0, seq_len), device=device, dtype=torch.long),
            'extra_msa_mask': torch.zeros((1, 0, seq_len), device=device),
            'extra_msa_row_mask': torch.zeros((1, 0), device=device),
        }
        
        print(f"âœ… æµ‹è¯•è¾“å…¥å‡†å¤‡å®Œæˆ:")
        print(f"   - åºåˆ—é•¿åº¦: {seq_len}")
        print(f"   - MSAæ·±åº¦: {msa_depth}")
        print(f"   - è®¾å¤‡: {device}")
        
        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼å¹¶ç¦ç”¨æ¢¯åº¦è®¡ç®—
        model.eval()
        with torch.no_grad():
            try:
                # åªè®¡ç®—è¡¨ç¤ºï¼Œä¸è®¡ç®—æŸå¤±
                output = model(batch)
                print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸ!")
                print(f"   - è¾“å‡ºé”®: {list(output.keys())}")
                if 'final_atom_positions' in output:
                    pos_shape = output['final_atom_positions'].shape
                    print(f"   - åŸå­åæ ‡å½¢çŠ¶: {pos_shape}")
                
                return True
            except torch.cuda.OutOfMemoryError:
                print("âš ï¸ GPUå†…å­˜ä¸è¶³ï¼Œå°è¯•æ›´å°çš„è¾“å…¥")
                return False
            except Exception as e:
                print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
                return False
                
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­æµ‹è¯•è®¾ç½®å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§¬ OpenFoldåŸºç¡€åŠŸèƒ½æµ‹è¯•")
    print("=" * 50)
    
    tests = [
        ("æ¨¡å‹åˆ›å»º", test_model_creation),
        ("æ•°æ®å˜æ¢", test_data_transforms), 
        ("CUDAå†…æ ¸", test_cuda_kernels),
        ("å‰å‘ä¼ æ’­", test_forward_pass),
    ]
    
    results = {}
    for test_name, test_func in tests:
        try:
            results[test_name] = test_func()
        except Exception as e:
            print(f"âŒ {test_name}æµ‹è¯•å¼‚å¸¸: {e}")
            results[test_name] = False
    
    print("\n" + "=" * 50)
    print("ğŸ† æµ‹è¯•ç»“æœæ€»ç»“:")
    
    passed = sum(results.values())
    total = len(results)
    
    for test_name, result in results.items():
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"   {test_name}: {status}")
    
    print(f"\næ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰åŸºç¡€åŠŸèƒ½æµ‹è¯•é€šè¿‡ï¼")
        print("ğŸ’¡ OpenFoldç¯å¢ƒé…ç½®å®Œå…¨æ­£ç¡®ï¼Œå¯ä»¥è¿›è¡Œç»“æ„é¢„æµ‹")
        print("ğŸ“ ä¸‹è½½æ¨¡å‹å‚æ•°åå³å¯å¼€å§‹ä½¿ç”¨")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 
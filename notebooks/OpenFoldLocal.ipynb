{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenFold Local Notebook\n",
    "\n",
    "Provides the flexibility to run inference using a local installation of OpenFold with Docker, along with the convenience of visualizing results using the same plots from the OpenFold Colab Notebook.\n",
    "\n",
    "This notebook uses the provided utility functions to execute OpenFold via Docker it adds logic to handle results, so you can experiment with different parameters, re-use computed msas, filter the best model, plot metrics and, async and handle long running executions.\n",
    "\n",
    "If you have access to a machine and want to do quick inference and visualize results, there are some useful things you can do with this notebook:\n",
    "\n",
    "- You can use precomputed alignments, which enables you to run inference with different model parameters to compare results\n",
    "- Get the best model and metric plots  \n",
    "- Handle long-running executions\n",
    "- Work with big datasets i.e split your input and perform async runs using asyncio on multiple GPUs\n",
    "\n",
    "Of course, you can do this solely using Docker commands in the terminal, but you would need to code/adjust the Colab functions to work with data locally. This notebook gives you a head start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the notebook\n",
    "\n",
    "Fist, build Openfold using Docker. Follow this [guide](https://openfold.readthedocs.io/en/latest/original_readme.html#building-and-using-the-docker-container).\n",
    "\n",
    "Start your notebook:\n",
    "\n",
    "Go to the notebook folder:\n",
    "\n",
    "`cd notebooks`\n",
    "\n",
    "Install the requirements in your env:\n",
    "\n",
    "`pip install -r utils/requirements.txt`\n",
    "\n",
    "Start your Jupyter server\n",
    "\n",
    "`jupyter lab . --ip=\"0.0.0.0\"`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Inference \n",
    "\n",
    "**Inputs:** files or strings with sequences\n",
    "\n",
    "**Output:** \n",
    "\n",
    "```bash\n",
    "data/ \n",
    "├── run_<run_id>/ # each is run stored with a random ID, this id can be use to re-run inference \n",
    "│   ├── fasta_dir/ \n",
    "│   │   ├── tmp/ # generated .fasta file per sequence\n",
    "│   │   └── sequences.fasta # validated input sequences are merged into a .fasta file\n",
    "│   └── output/\n",
    "│       ├── alignments/ #  one folder per sequence of resulted MSA\n",
    "│       ├── predictions/ # inference results .pkl and .pdb files\n",
    "│       └── timings.json # inference time\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage 1: Using a sequence string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import InferenceClientOpenFold\n",
    "\n",
    "# Initialize the OpenFold Docker client setting the database path \n",
    "databases_dir = \"/home/juliocesar/DataZ/Models/alphafold_all_data\"\n",
    "openfold_client = InferenceClientOpenFold(databases_dir)\n",
    "\n",
    "# Set the input, for multiple sequences, separate sequences with a colon `:`\n",
    "input_string = \"DAGAQGAAIGSPGVLSGNVVQVPVHVPVNVCGNTVSVIGLLNPAFGNTCVNA:AGETGRTGVLVTSSATNDGDSGWGRFAG\"\n",
    "\n",
    "model_name = \"multimer\"\n",
    "weight_set = 'AlphaFold'\n",
    "\n",
    "\n",
    "# Run inference\n",
    "run_id = openfold_client.run_inference(weight_set, model_name, inference_input=input_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage 2: Using a fasta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"/home/juliocesar/Models/openfold/notebooks/data/test.fasta\"\n",
    "\n",
    "run_id = openfold_client.run_inference(weight_set, model_name, inference_input=input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage 3: Using a pre-computed aligments for a run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openfold_client.run_inference(weight_set, model_name, use_precomputed_alignments=True, run_id=\"8CJUIY\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signalp-6.0",
   "language": "python",
   "name": "signalp-6.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
